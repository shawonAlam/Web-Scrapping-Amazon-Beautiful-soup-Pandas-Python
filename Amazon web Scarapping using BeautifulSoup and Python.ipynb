{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843ccd11-d2a3-424e-9216-b0292a4daa38",
   "metadata": {},
   "source": [
    "## Amazon URL scrapped using Beautiful Soup and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795c02e-334f-4ae9-8732-cb9b00948fae",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "180234a6-06b9-4d27-9b2b-a861463168fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d05ac8-22e3-43f7-b10f-6f283b15cb5c",
   "metadata": {},
   "source": [
    "### functions for Title, Price, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0b08c79-41b1-465b-baad-256245aa27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for title, price, rating\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(id = \"productTitle\").get_text()\n",
    "        title = title.strip()\n",
    "        #print(title)\n",
    "    except AttributeError:\n",
    "        title = \"\"\n",
    "    return title\n",
    "            \n",
    "\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price_symblo = soup.find(class_ = \"a-price-symbol\").get_text()\n",
    "        price_whole = soup.find(class_ = \"a-price-whole\").get_text()\n",
    "        price_fraction = soup.find(class_ = \"a-price-fraction\").get_text()\n",
    "        price = f'{price_symblo}{price_whole}{price_fraction}'\n",
    "        price = price.strip()\n",
    "        #print(price)\n",
    "    except AttributeError:\n",
    "        price = \"\"\n",
    "    return price\n",
    "\n",
    "\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find(class_ = \"a-icon-alt\").get_text()\n",
    "        print(rating)\n",
    "    except AttributeError:\n",
    "        rating = \"\"\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee48e8c-acc0-4dc0-a1c2-35d0211130b6",
   "metadata": {},
   "source": [
    "### main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8915fb8c-12ac-40d6-bd97-70a519e87661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total items: 68\n",
      "69\n",
      "4.5 out of 5 stars\n",
      "1 item found\n",
      "Previous page\n",
      "2 item found\n",
      "Previous page\n",
      "3 item found\n",
      "Previous page\n",
      "4 item found\n",
      "4.2 out of 5 stars\n",
      "5 item found\n",
      "4.4 out of 5 stars\n",
      "6 item found\n",
      "4.5 out of 5 stars\n",
      "7 item found\n",
      "4.5 out of 5 stars\n",
      "8 item found\n",
      "Previous page\n",
      "9 item found\n",
      "5.0 out of 5 stars\n",
      "10 item found\n",
      "Previous page\n",
      "11 item found\n",
      "Previous page\n",
      "12 item found\n",
      "5.0 out of 5 stars\n",
      "13 item found\n",
      "5.0 out of 5 stars\n",
      "14 item found\n",
      "Previous page\n",
      "15 item found\n",
      "Previous page\n",
      "16 item found\n",
      "Previous page\n",
      "17 item found\n",
      "Previous page\n",
      "18 item found\n",
      "Previous page\n",
      "19 item found\n",
      "Previous page\n",
      "20 item found\n",
      "4.2 out of 5 stars\n",
      "21 item found\n",
      "4.5 out of 5 stars\n",
      "22 item found\n",
      "4.5 out of 5 stars\n",
      "23 item found\n",
      "4.5 out of 5 stars\n",
      "24 item found\n",
      "Previous page\n",
      "25 item found\n",
      "Previous page\n",
      "26 item found\n",
      "Previous page\n",
      "27 item found\n",
      "Previous page\n",
      "28 item found\n",
      "4.3 out of 5 stars\n",
      "29 item found\n",
      "4.5 out of 5 stars\n",
      "30 item found\n",
      "4.5 out of 5 stars\n",
      "31 item found\n",
      "4.4 out of 5 stars\n",
      "32 item found\n",
      "Previous page\n",
      "33 item found\n",
      "Previous page\n",
      "34 item found\n",
      "Previous page\n",
      "35 item found\n",
      "5.0 out of 5 stars\n",
      "36 item found\n",
      "3.9 out of 5 stars\n",
      "37 item found\n",
      "4.2 out of 5 stars\n",
      "38 item found\n",
      "4.6 out of 5 stars\n",
      "39 item found\n",
      "Previous page\n",
      "40 item found\n",
      "Previous page\n",
      "41 item found\n",
      "Previous page\n",
      "42 item found\n",
      "Previous page\n",
      "43 item found\n",
      "5.0 out of 5 stars\n",
      "44 item found\n",
      "5.0 out of 5 stars\n",
      "45 item found\n",
      "Previous page\n",
      "46 item found\n",
      "Previous page\n",
      "47 item found\n",
      "Previous page\n",
      "48 item found\n",
      "Previous page\n",
      "49 item found\n",
      "Previous page\n",
      "50 item found\n",
      "5.0 out of 5 stars\n",
      "51 item found\n",
      "5.0 out of 5 stars\n",
      "52 item found\n",
      "Previous page\n",
      "53 item found\n",
      "5.0 out of 5 stars\n",
      "54 item found\n",
      "Previous page\n",
      "55 item found\n",
      "Previous page\n",
      "56 item found\n",
      "Previous page\n",
      "57 item found\n",
      "Previous page\n",
      "58 item found\n",
      "5.0 out of 5 stars\n",
      "59 item found\n",
      "5.0 out of 5 stars\n",
      "60 item found\n",
      "5.0 out of 5 stars\n",
      "61 item found\n",
      "Previous page\n",
      "62 item found\n",
      "Previous page\n",
      "63 item found\n",
      "Previous page\n",
      "64 item found\n",
      "4.2 out of 5 stars\n",
      "65 item found\n",
      "4.5 out of 5 stars\n",
      "66 item found\n",
      "4.5 out of 5 stars\n",
      "67 item found\n",
      "4.5 out of 5 stars\n",
      "68 item found\n",
      "4.6 out of 5 stars\n",
      "69 item found\n",
      "Data added to csv file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User.SHAWONALAM\\AppData\\Local\\Temp\\ipykernel_3572\\1471326640.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Title'].replace('', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def scrap_link():\n",
    "    # add your user agent \n",
    "    HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "    #URL\n",
    "    URL = \"https://www.amazon.com/s?k=data%2Banalyst%2Btshirt&crid=3439HC17FJ9CY&sprefix=data%2Banalyst%2Btshirt%2Caps%2C290&ref=nb_sb_noss_1\"\n",
    "    # HTTP Request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    # Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "    print(\"total items: \" + str(len(links) - 1))\n",
    "    \n",
    "    # Store the links\n",
    "    links_list = []\n",
    "\n",
    "    # Loop for extracting links from Tag Objects\n",
    "    for link in links:\n",
    "            links_list.append(link.get('href'))\n",
    "    print(len(links_list))\n",
    "    d = {\"Title\":[], \"Price\":[], \"Rating\":[]}\n",
    "    link_num_count = 1\n",
    "    for link in links_list:\n",
    "        new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
    "        \n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        #functions to append\n",
    "        d['Title'].append(get_title(new_soup))\n",
    "        d['Price'].append(get_price(new_soup))\n",
    "        d['Rating'].append(get_rating(new_soup))\n",
    "\n",
    "        print(str(link_num_count) + \" item found\")\n",
    "        link_num_count += 1\n",
    "        #if link_num_count == 6:\n",
    "            #break\n",
    "    #Adding data to data frame \n",
    "    df = pd.DataFrame.from_dict(d)\n",
    "    df['Title'].replace('', np.nan, inplace=True)\n",
    "    \n",
    "    df = df.dropna(subset=['Title'])\n",
    "    df.to_csv(\"Amazon web scrapping dataset.csv\", header=True, index=False)\n",
    "    print(\"Data added to csv file\")\n",
    "\n",
    "scrap_link()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05763321-1e41-49a1-b994-38c427f632e8",
   "metadata": {},
   "source": [
    "### data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2508f2c6-113f-46d9-ad9a-d778284d5554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title   Price  \\\n",
      "0   NORTHYARD Men's Athletic Running T-Shirts Quic...  $21.99   \n",
      "1   Data Analyst Definition Data Analysis Distress...   $9.99   \n",
      "2   Got Data? Data Analyst Programmer Accountant D...   $9.99   \n",
      "3   Talk Data To Me Data Analyst Programmer Data A...   $9.99   \n",
      "4   KLIEGOU Men's T-Shirts - Premium Cotton Crew N...  $24.99   \n",
      "..                                                ...     ...   \n",
      "64  KLIEGOU Men's T-Shirts - Premium Cotton Crew N...  $24.99   \n",
      "65  Gildan Unisex-Adult Ultra Cotton T-Shirt, Styl...  $39.99   \n",
      "66  Gildan Unisex-Adult Heavy Cotton T-Shirt, Styl...  $34.99   \n",
      "67  Gildan Unisex-Adult Softstyle Cotton T-Shirt, ...  $11.70   \n",
      "68  Gildan Adult DryBlend Workwear T-Shirts with P...  $17.64   \n",
      "\n",
      "                Rating  \n",
      "0   4.5 out of 5 stars  \n",
      "1        Previous page  \n",
      "2        Previous page  \n",
      "3        Previous page  \n",
      "4   4.2 out of 5 stars  \n",
      "..                 ...  \n",
      "64  4.2 out of 5 stars  \n",
      "65  4.5 out of 5 stars  \n",
      "66  4.5 out of 5 stars  \n",
      "67  4.5 out of 5 stars  \n",
      "68  4.6 out of 5 stars  \n",
      "\n",
      "[69 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\User.SHAWONALAM\\Amazon web scrapping dataset.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be991aa6-1d68-45dc-8601-876c17f3ce17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
